---
title: "Measuring Group Differences in High-Dimensions"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/flori/OneDrive/_MSc Economics/Semester III/ML for Economics/Empirical Project")

library(dplyr)
library(tidyr)
library(ggplot2)
```

The paper Gentzkow et al. 2019 aims at measuring political partisanship in the US since 1870 by analyzing the extent to which different party members choose different words when making speeches in congress.

This notebook applies the methodology suggested by Gentzkow et al. 2019 to a simulated dataset of speeches given by politicians over 100 sessions.The objective is to reliably estimate systematic differences in choice probabilities if the choice set is large (relative to the number of choices made), i.e., if random drawing from the choice set by itself leads to different choices made which are driven by randomness and not by differences in choice probabilities. To understand this problem intuitively, think of politicians of choosing a single word from a list of 1000 options, all choices being made with probability 0.1%. In that case, there is no partisanship as choice probabilities are identical for all politicians, but the observed choices will most surely be different. If we just look at realized choices, we overestimate differences when the choice set is large (relative to the number of choices made). Note that the higher the number of draws from the choice probabilities, the more similar realized choices are. 

I cannot work with real speech data due to limitations in computation space and time (Gentzkow et al. look at a choice set of over 200,000 phrases). However, I aim at incorporating all important elements from the original paper, although in a simpler form. This means that in the simulated data
- choice probabilities are affected by party affiliation (this is the effect I want to estimate) and demographic variables (age and home state of the politicians)
- the effect size of party affiliation only starts to pick up in the last third of the data (partisanship rises)
- the number of choices made per speaker (length of speech) varies over time
- the choice set itself varies (increases parallel to speech length)
Thereby, I replicate the behavior of the real US data shown below:
```{r}
read.table("appendix_table_1.txt", header=FALSE, sep=" ") %>%
  mutate(draws_per_speaker = (V6 + V7) / V4 * 20) %>%
  rename(choice_set = V5, session = V3) %>%
  ggplot(aes(x = session)) +
  geom_line(aes(y = choice_set, color = "Choice set")) + 
  geom_line(aes(y = draws_per_speaker, color = "Draws")) +
  scale_y_continuous(
    name = "Choice Set",
    sec.axis = sec_axis(~ ./20, name = "Draws")
  ) +
  scale_color_manual(values = c("Choice set" = "blue", "Draws" = "green")) +
  labs(color = "Legend") + 
  ggtitle("Changes in verbosity and size of choice set in original data")
```

```{r}
read.table("appendix_table_1.txt", header=FALSE, sep=" ") %>%
  mutate(draws_per_choices = ((V6 + V7) / V4) / V5) %>%
  rename(session = V3) %>%
  ggplot(aes(x=session,y=draws_per_choices)) + geom_line() +
  ggtitle("Draws per speaker relative to size of choice set")
```

## Simuating the data
To generate the sample, I first create a sample of 100 politicians with different party affiliations and origins (from 20 different regions). Note that different from the real data, these demographics stay constant over time (which does not matter a lot for the exercise):
```{r}
# Create 100 politicians
id <- 1:100
party <- sample(c(rep(0, 50), rep(1, 50)))
age <- as.integer(rnorm(100, mean = 60, sd = 10))
origin <- sample(10:20,100,replace=TRUE)
base <- data.frame(id = id, party = party, age = age, origin = origin)
head(base)
```

Now I use a Multinomial Logit Model to generate utilities for each choice in the choice set which depend on the speaker's characteristics. Specifically, I calculate utility from using a phrase $j$ (choosing a high $J \geq 1000$) in session $t$ as a function of party affiliation $P_i$, speaker age $A_{i}$ and origin $O_i$ (to introduce some demographic variation), and an individual error term: $$u_{jit} = \pi_t \cdot \alpha_j \cdot P_i + \beta_1 \cdot A_{i} + \beta_2 \cdot O_i + \epsilon_{it}$$. Note that the parameter $\pi_t$ determines partisanship, in the sense that if $\pi_t=0$ party affiliation does not matter for choice probabilities.
```{r}
# Set parameters

alpha <- c(1,0.5) # shapes gamma-distribution
beta1 <- c(0,0.1) # shapes unifrom-distribution
beta2 <- c(0.5,0.7) # shapes unifrom-distributin
  # effect sizes are not scale-invariant, still in this setup origin matters more
pi <- c(rep(0.8, 70), seq(0.82, 1.4, length.out = 30))
  # partisanship increasing in last 30 session
ndraws <- c(rep(50,50),seq(52, 100, length.out = 25),rep(100,25))
  # number of draws (speech length) increasing in session 50-75
nchoices <- c(rep(1000,100))
#nchoices <- c(rep(1000,50),seq(1010, 1500, length.out = 50))
  # choice set grows linearly in session 50-100
J <- max(nchoices)

hist(rgamma(J, shape = alpha[1], scale = alpha[2]),
     main="Distribution of party-effect on choice utilities (distribution over all choices)")
```

With the parameters set for all choices, we can simulate a session by 
1. calculating utilities for all choices
2. deriving choice probabilities from utilities
3. letting each politician draw $n$ times from the choice set
(see file `simulation.R`)
```{r}
source("simulation.R")

simulate_session(base,alpha,beta1,beta2,pi[1],ndraws[1],nchoices[1],J) %>%
  pivot_longer(starts_with("V"),names_to="choice",values_to="total_occurences") %>%
  filter(!is.na(choice)) %>%
  ggplot(aes(x=choice,y=total_occurences,fill=factor(party))) + geom_bar(stat="identity") +
  ggtitle("Total draws of each choice per party") + 
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

We can see that our data is very sparse, as many choices are barely chosen by any party. Note that this is the result of (1) choice probabilities being low due to the many options and (2) the choice set being restricted to a subset of choices at the beginning (since the effective choice set grows over time).

Now we simulate data for all years
```{r}
#pb <- txtProgressBar(1,100,style=3)
data <- simulate_session(base,alpha,beta1,beta2,pi[1],ndraws[1],nchoices[1],J)
for (t in 2:100) {
    data <- rbind(data,simulate_session(base,alpha,beta1,beta2,pi[t],ndraws[t],nchoices[t],J))
    #setTxtProgressBar(pb,t)
}
#close(pb)
data$session <- rep(1:100, each = 100)
data_agg <- data %>%
    select(party:session) %>%
    group_by(party, session) %>%
    summarize(across(V1:paste("V",max(nchoices),sep=""), ~ mean(.x, na.rm = TRUE)))

#wb <- createWorkbook()
#addWorksheet(wb, "micro")
#addWorksheet(wb, "aggregated")
#writeData(wb, "micro", data)  # Replace with your first data frame
#writeData(wb, "aggregated", data_agg)  # Replace with your second data frame
#saveWorkbook(wb, "simulated_data.xlsx", overwrite = TRUE)
```

## Analyzing the data
As a starting point, we could try to just use the first estimator that would come to mind for measuring a difference in choice vectors. For example, we could just take the absolute mean difference between all choices for party 0 vs party 1. What happens when we estimate partisanship in such a naive way?
```{r}
data_long <- data_agg %>%
    pivot_longer(
        cols = starts_with("V"),
        names_to = "phrase",
        values_to = "count"
    ) %>%
  pivot_wider(
    names_from = party,
    values_from = count,
    names_prefix = "party_"
  )

data_long$difference = abs(data_long$party_0 - data_long$party_1)

data_long %>%
  mutate(ndraws = rep(ndraws,each=J)) %>%
  group_by(session) %>%
  summarize(mean_difference = mean(difference,na.rm=TRUE),
            draws_per_speaker = mean(ndraws,na.rm=TRUE) / 1000) %>%
  ggplot(aes(x = session)) +
  geom_line(aes(y = mean_difference, color = "Estimator")) + 
  geom_line(aes(y = draws_per_speaker, color = "Draws")) +
  scale_y_continuous(
    name = "Estimator",
    sec.axis = sec_axis(~ . *1000, name = "Draws")
  ) +
  scale_color_manual(values = c("Estimator" = "blue", "Draws" = "green")) +
  labs(color = "Legend") + 
  ggtitle("A bad estimator for partisanship (mean absolut difference)")
```

We see that we pick up an increase in partisanship from session 50 onwards, although partisanship really increases only after session 70. This is due to the fact the the number of draws increases, meaning that more observations are observed and larger absolute differences become more likely. Note that with a large choice set, there are many zeros so that the mean is pushed towards zero.

Another problem with taking the absolute mean difference as a measure is that it has no real-world interpretation. For that reason, Gentzkow et al. 2019 propose as measure the probability of an outsider observer guessing party affiliation right after hearing just one phrase. Intuitively, this theoretical value of that measure is 0.5 if there is no partisanship (if we could observe an infinite number of choices) and 1 for complete partisanship (there is no phrased used by both parties).
```{r}
data_long$ndraws <- rep(ndraws,each=J)

data_long$q0 <- data_long$party_0
data_long$q1 <- data_long$party_1
data_long$rho <- data_long$q1 /(data_long$q0+data_long$q1)
                  # if phrase never used, then rho = NA
data_long$partisanship <- data_long$q1*data_long$rho + data_long$q0*(1-data_long$rho) + 0.5
                  # add 0.5 for neutral prior (?)

biased_estimates <- (data_long %>%
    group_by(session) %>%
    summarize(mean_partisanship = mean(partisanship,na.rm=TRUE)))$mean_partisanship

data_long %>%
  group_by(session) %>%
  summarize(mean_partisanship = mean(partisanship,na.rm=TRUE)) %>%
  ggplot(aes(x=session,y=mean_partisanship)) + geom_line() +
  ggtitle("Naive partisanship measure")
```

First solution is leave-one-out estimator. Intuitively, the high-dimensionality problem leads to the fact that a choice made by a single politicians alone strongly influenced the derived choice probability for his party. Thereby, for some phrases estimates for $P(j|R)$ and $P(R|j)$ may both stem primarily from the same observation, leading to undesired correlation in the error for both estimates (if our estimate for the former is bad, so automatically is the estimate for the latter). Therefore, we now calculate them from two different samples: One is a single individual, the other is all the other politicians.
```{r}
# merge long data to individual one 
data_combined <- merge((data %>% pivot_longer(cols=starts_with("V"),names_to="phrase",values_to="q_i")),
      (data_long),by=c("session","phrase"))

data_combined$ndraws <- rep(ndraws,each=J)

# drop observation i from party phrase-counts:
data_combined <- data_combined %>%
  mutate(party_0_loo = party_0 - q_i * abs(party-1),
         party_1_loo = party_1 - q_i * party)

data_combined$q0 <- data_combined$party_0_loo / (data_combined$ndraws*49)
data_combined$q1 <- data_combined$party_1_loo / (data_combined$ndraws*49)
data_combined$rho <- data_combined$q1 /(data_combined$q0+data_combined$q1)
                  # if phrase never used, then rho = NA
data_combined$partisanship <- data_combined$q_i*data_combined$rho + data_combined$q_i *(1-data_combined$rho) + 0.5

loo_estimates <- (data_combined %>%
    group_by(session) %>%
    summarize(mean_partisanship = mean(partisanship,na.rm=TRUE)))$mean_partisanship

data_combined %>%
  group_by(session) %>%
  summarize(mean_partisanship = mean(partisanship,na.rm=TRUE)) %>%
  ggplot(aes(x=session,y=mean_partisanship)) + geom_line() +
  ggtitle("Leave-one-out partisanship measure")
```

Now we subtract the bias from the naive estimates and find that we indeed primarily pick up the increase in partisanship from period 70 onwards.
```{r}
data.frame(session=1:100,biased_estimates=biased_estimates,loo_estimates=loo_estimates) %>%
  mutate(corrected_estimates = biased_estimates - loo_estimates + 0.5) %>%
  ggplot(aes(x=session,y=corrected_estimates)) + geom_line() +
  geom_smooth(method = "loess", se = FALSE)  +
  geom_vline(xintercept = 70, linetype = "dashed", color = "black") +
  ggtitle("Partisanship estimates corrected by LOO-estimates")
```
```{r}
library(glmnet)

results_ridge <- data.frame(session = numeric(0), j = numeric(0),
                    alpha = numeric(0), alpha_estimate = numeric(0),
                    lambda = numeric(0), ndraws = numeric(0))
lambdas <- c(0,10)

#pb <- txtProgressBar(1,100,style=3)
for (t in 1:100) {
  for (j in 1:J) {
    if (length(unique(data[data$session==t,paste("V",j,sep="")])) > 1) {
        # necessary because sometimes no variations in y
      model <- glmnet(x=data[data$session==t,c("party","age")],
                  y=data[data$session==t,paste("V",j,sep="")],
                  penalty.factor=c(1,0),alpha=0)
      for (l in lambdas) {
        results_ridge <- rbind(results_ridge, data.frame(session = t,
                                             j = paste("V",j,sep=""),
                                             alpha_estimate = coef(model,s=l)[2],
                                             lambda = l,
                                             ndraws = ndraws[t]))
      }}
      else {
        for (l in lambdas) {
          results_ridge <- rbind(results_ridge, data.frame(session = t,
                                             j = paste("V",j,sep=""),
                                             alpha_estimate = NA,
                                             lambda = l,
                                             ndraws = ndraws[t])) }
    }
  }
  #setTxtProgressBar(pb,t)
}
#close(pb)
```

```{r}
results_ridge %>%
  group_by(session, lambda) %>%
  summarize(mean_alpha = mean(abs(alpha_estimate),na.rm=TRUE),
            true_mean_alpha = mean(alpha),na.rm=TRUE) %>%
  ggplot(aes(x = session)) +
  geom_line(aes(y = mean_alpha, color = factor(lambda))) +
   geom_smooth(aes(y = mean_alpha, color = factor(lambda)), method = "loess", se = FALSE)  +
  #geom_line(aes(y = true_mean_alpha), color = "black") +
  ggtitle("Shrinkage of party affiliation effects")

```

We now develop our own simple approach to address the bias with a prior. The idea is to add a value $k$ to all observed choices made. Intuitively, if we observed a phrase 2 times from party 1 and once from party 0, we would estimate that it is twice as likely that party 1 uses that words than party 0 (very partisan phrase). By adding $k=1$, for example, we would say that it is only $3/2 = 1.5$ times more likely that party 1 uses that word relative to party 0. This shows that our approach shrinks the partisan-effect just as the ridge regression (indeed, in a Bayesian framework ridge-regressions do exactly the same as our approach, namely adding a particularily distributed prior to all observations).
```{r}
df <- data_long
df$ndraws <- rep(ndraws,each=J)

df$q0 <- df$party_0
df$q1 <- df$party_1
df$rho <- df$q1 /(df$q0+df$q1)
                  # if phrase never used, then rho = NA
df$partisanship <- df$q1*df$rho + df$q0*(1-df$rho) + 0.5
                  # add 0.5 for neutral prior (?)

df %>%
  group_by(session) %>%
  summarize(mean_partisanship = mean(partisanship,na.rm=TRUE)) %>%
  ggplot(aes(x=session,y=mean_partisanship)) + geom_line() +
  ggtitle("Naive partisanship measure (k=0)")
```
```{r}

results_beta <- data.frame(session=numeric(0) ,k = numeric(0), partisanship = numeric(0))
  
for (k in c(0,0.001,0.01,0.1)) {
  df$q0 <- (df$party_0+k) / (df$ndraws + k*J) * 50
  df$q1 <- (df$party_1+k) / (df$ndraws + k*J) * 50
  df$rho <- df$q1 /(df$q0+df$q1)
                    # if phrase never used, then rho = NA
  df$partisanship <- df$q1*df$rho + df$q0*(1-df$rho) + 0.5
                    # add 0.5 for neutral prior (?)
  results_beta <- rbind(results_beta, data.frame(session=1:100,
                                                 k = rep(k,100),
                                                 partisanship = (df %>%
                                                        group_by(session) %>%
                                                        summarize(mean = mean(partisanship,na.rm=TRUE)))$mean))
}

results_beta %>%
  #filter(k %in% c(0,0.5,1,2,5,10,25,50,100)) %>%
  ggplot(aes(x=session,y=partisanship,color=factor(k))) + geom_line() +
   geom_smooth(aes(y = partisanship, color = factor(k)), method = "loess", se = FALSE)  +
   geom_vline(xintercept = 70, linetype = "dashed", color = "black")+
  ggtitle("Corrected partisanship measures (true increase from session 70 onwards)")
```

We find that our approach, although being much simples and saving a lot of computation time, is also successful in isolating the effect from partisanship changes from changes in verbosity. The next step is to optimally choose the regularization parameter $k$.